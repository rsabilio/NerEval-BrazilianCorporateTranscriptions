{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1WtrfSROzlWi"
   },
   "source": [
    "# T5-based models Fine-tuning and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalando pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44552,
     "status": "ok",
     "timestamp": 1705671157094,
     "user": {
      "displayName": "Ramon Abilio",
      "userId": "08110625410162679749"
     },
     "user_tz": 180
    },
    "id": "IohFvtFr4pES",
    "outputId": "77fb4782-14d9-4276-b2c7-664f8d5dc02d"
   },
   "outputs": [],
   "source": [
    "!pip install --quiet transformers sentencepiece datasets seqeval evaluate accelerate -U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "2781b2c6c2004cc8a06991dde91d9800",
      "73131803c39a462fbad2e2a32150d31c",
      "ffdd1b8e5645463db8e99aecf3724668",
      "f8d45f7ccc864246942b97166d5fe06f",
      "a408860726ef406d87ec946b9bd84de0",
      "bda6326bbd7e4d0da0d9aa9fcdfb252e",
      "d602c5cd2a864c6a99d3b6477aef185a",
      "1e885c86c5fe4fc2a5795c1efd178711",
      "9db2193eda5d45f3b8ecad5a052eff01",
      "73bdb41b61d146aab1281112f335bd35",
      "e168f2c257f147dca8e99d640d81ad58"
     ]
    },
    "executionInfo": {
     "elapsed": 31511,
     "status": "ok",
     "timestamp": 1705671188594,
     "user": {
      "displayName": "Ramon Abilio",
      "userId": "08110625410162679749"
     },
     "user_tz": 180
    },
    "id": "nMr7-png8BdY",
    "outputId": "8dbf978c-a2fa-4c77-df9d-d01f5175525d"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from datasets import load_from_disk\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "from transformers import AutoTokenizer, T5ForConditionalGeneration, MT5Tokenizer, MT5ForConditionalGeneration\n",
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "metric = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Ab5G7Or49S-"
   },
   "source": [
    "## Carregando Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1705671208741,
     "user": {
      "displayName": "Ramon Abilio",
      "userId": "08110625410162679749"
     },
     "user_tz": 180
    },
    "id": "jGtBBoV84_w3",
    "outputId": "88037344-1bd2-43bb-8458-891f5543a79c"
   },
   "outputs": [],
   "source": [
    "root_folder = './'\n",
    "data_folder = f'{root_folder}/datasets/'\n",
    "\n",
    "# PTT5\n",
    "model_name     = \"unicamp-dl/ptt5-base-portuguese-vocab\"\n",
    "model_nickname = \"ptt5\"\n",
    "\n",
    "# mT5\n",
    "#model_name     = \"google/mt5-small\"\n",
    "#model_nickname = \"mt5\"\n",
    "\n",
    "model_folder = f\"{root_folder}/{model_nickname}\"\n",
    "\n",
    "print(model_name)\n",
    "print(model_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1705671208742,
     "user": {
      "displayName": "Ramon Abilio",
      "userId": "08110625410162679749"
     },
     "user_tz": 180
    },
    "id": "-WeAlmHVlU9a",
    "outputId": "3d9f79ae-cb2f-4035-c877-63db78132e12"
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_ent_label(model_output):\n",
    "\n",
    "  tokens = model_output.split()\n",
    "  predicted_labels = []\n",
    "  for token in tokens:\n",
    "    if \"|\" in token:\n",
    "      parts = token.split(\"|\")\n",
    "      ent   = parts[0].replace('[','').split('_')\n",
    "      label = parts[1].split(']')[0]\n",
    "\n",
    "      predicted_labels.append(\"B-\"+label)\n",
    "      for i in range(1, len(ent)):\n",
    "        predicted_labels.append(\"I-\"+label)\n",
    "\n",
    "    else:\n",
    "     if token not in ['[','|',']']:\n",
    "       predicted_labels.append(\"O\")\n",
    "\n",
    "  return predicted_labels\n",
    "\n",
    "\n",
    "#text = 'Vemos que o saldo dessa [carteira|CARTEIRA] 123 [carteira_de_crédito|CARTEIRA] em março de 2014 é bastante superior ao dos demais bancos, permitindo ao BB encerrar o período com [27,1%|PERCENTUAL]? de participação de mercado.'\n",
    "#get_ent_label(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TXff5zPc21PP"
   },
   "source": [
    "## Treinando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8UkYOOPwnBse"
   },
   "outputs": [],
   "source": [
    "if model_nickname == 'mt5':\n",
    "    model     = MT5ForConditionalGeneration.from_pretrained(model_name, max_length=512, return_dict = True)\n",
    "    tokenizer = MT5Tokenizer.from_pretrained(model_name, legacy=False)\n",
    "else:\n",
    "    model     = T5ForConditionalGeneration.from_pretrained(model_name, max_length=512, return_dict = True)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, legacy=False) \n",
    "    \n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dkQmGgk_B7py"
   },
   "outputs": [],
   "source": [
    "dataset = load_from_disk(f\"{model_folder}/dataset-bancos-{model_nickname}\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aivEDvYRHgnU"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "\n",
    "    batch_size = 4\n",
    "    refs = []\n",
    "    for i in range(0, len(labels), batch_size):\n",
    "      l = labels[ i : i + batch_size]\n",
    "      l[ l < 0 ] = tokenizer.pad_token_id\n",
    "      batch = tokenizer.batch_decode(l, skip_special_tokens=True)\n",
    "      refs.extend(batch)\n",
    "\n",
    "    refs = [ get_ent_label(t) for t in refs ]\n",
    "\n",
    "    preds = []\n",
    "    for i in range(0, len(predictions), batch_size):\n",
    "      preds.extend(tokenizer.batch_decode(predictions[ i : i + batch_size], skip_special_tokens=True))\n",
    "\n",
    "    preds = [ get_ent_label(p) for p in preds ]\n",
    "\n",
    "    # fazendo padding para que a listas tenham o mesmo tamanho\n",
    "    for idx in range(len(refs)):\n",
    "\n",
    "      if len(refs[idx]) > len(preds[idx]):\n",
    "        diff = len(refs[idx]) - len(preds[idx])\n",
    "        preds[idx] = preds[idx] + ['O']*diff\n",
    "\n",
    "      if len(refs[idx]) < len(preds[idx]):\n",
    "        diff = len(preds[idx]) - len(refs[idx])\n",
    "        refs[idx] = refs[idx] + ['O']*diff\n",
    "\n",
    "\n",
    "    results = metric.compute(predictions=preds, references=refs, zero_division=0)\n",
    "\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "executionInfo": {
     "elapsed": 6445998,
     "status": "ok",
     "timestamp": 1705632061355,
     "user": {
      "displayName": "Ramon Abilio",
      "userId": "08110625410162679749"
     },
     "user_tz": 180
    },
    "id": "9KB4EVSYIHqp",
    "outputId": "af7c8d51-b021-4066-81eb-70935bdc4958"
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "logging_steps = dataset['train'].num_rows // batch_size\n",
    "epochs = 2\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir                  = f\"{model_folder}/results\",\n",
    "    num_train_epochs            = epochs,\n",
    "    per_device_train_batch_size = batch_size,\n",
    "    per_device_eval_batch_size  = batch_size,\n",
    "    evaluation_strategy         = \"epoch\",\n",
    "    disable_tqdm                = False,\n",
    "    logging_steps               = logging_steps,\n",
    "    fp16                        = (model_nickname == 'ptt5'),\n",
    "    predict_with_generate       = True,\n",
    "    save_total_limit            = 3,\n",
    "    learning_rate               = 0.001 if model_nickname == 'mt5' else 5e-5\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset['train'].remove_columns([\"text\",\"target\"]), \n",
    "    eval_dataset=dataset['validation'].remove_columns([\"text\",\"target\"]),\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X7vNRYvkIQ-w"
   },
   "outputs": [],
   "source": [
    "trainer.save_model(f\"{model_folder}/financial_ner_{model_nickname}/model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l2WJEyd4xo0o"
   },
   "source": [
    "## Avaliando modelo com conjunto de Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1c_fKuz4FbM-"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1705671208743,
     "user": {
      "displayName": "Ramon Abilio",
      "userId": "08110625410162679749"
     },
     "user_tz": 180
    },
    "id": "RY_yq-sMyXCT",
    "outputId": "ec761f07-b574-4ab0-decc-7d80c9d68f0d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26326,
     "status": "ok",
     "timestamp": 1705671235052,
     "user": {
      "displayName": "Ramon Abilio",
      "userId": "08110625410162679749"
     },
     "user_tz": 180
    },
    "id": "J_GKOH7Q9N_6",
    "outputId": "07badb9b-e3fc-41c4-d721-5523d0abb95e"
   },
   "outputs": [],
   "source": [
    "if model_nickname == 'mt5':\n",
    "    model     = MT5ForConditionalGeneration.from_pretrained(f\"{model_folder}/financial_ner_{model_nickname}/model\").to(device)\n",
    "    tokenizer = MT5Tokenizer.from_pretrained(f\"{model_folder}/financial_ner_{model_nickname}/model\", model_max_length=512)\n",
    "else:\n",
    "    model     = T5ForConditionalGeneration.from_pretrained(f\"{model_folder}/financial_ner_{model_nickname}/model\").to(device)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(f\"{model_folder}/financial_ner_{model_nickname}/model\", model_max_length=512)\n",
    "\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5145,
     "status": "ok",
     "timestamp": 1705671240181,
     "user": {
      "displayName": "Ramon Abilio",
      "userId": "08110625410162679749"
     },
     "user_tz": 180
    },
    "id": "hBA7PZidsnmZ",
    "outputId": "b21a8949-2d9e-4546-d732-5f10256d4884"
   },
   "outputs": [],
   "source": [
    "dataset = load_from_disk(f\"{model_folder}/dataset-bancos-{model_nickname}\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1454047,
     "status": "ok",
     "timestamp": 1705672812122,
     "user": {
      "displayName": "Ramon Abilio",
      "userId": "08110625410162679749"
     },
     "user_tz": 180
    },
    "id": "58GR--IfHl0F",
    "outputId": "44c75e4b-41d7-488e-e5af-f255a557d1c4"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# fazendo o padding e recuperando os tensors de mesmo tamanho\n",
    "dataset_test = dataset['test'].remove_columns(['text', 'target'])\n",
    "dataset_test = tokenizer.pad(dataset_test.to_dict())\n",
    "\n",
    "ans = []\n",
    "batch_size = 16\n",
    "len_dataset = len(dataset_test['input_ids'])\n",
    "for i in range(0, len_dataset, batch_size):\n",
    "  print(f\"\\r{i}/{len_dataset} \", end=\"\")\n",
    "\n",
    "  input = torch.as_tensor(dataset_test['input_ids'][i : i + batch_size]).to(device)\n",
    "  res = model.generate(input\n",
    "                      , max_length=512\n",
    "                      , num_beams=2\n",
    "        ).to(device)\n",
    "\n",
    "  ans.extend(res.tolist())\n",
    "\n",
    "len_dataset, len(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uOnztTsj1AvS"
   },
   "outputs": [],
   "source": [
    "with open(f\"{model_folder}/predictions-{model_nickname}.pkl\", 'wb') as fp:\n",
    "    pickle.dump(ans, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cálculo das métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8TaXbICR1ZBM"
   },
   "outputs": [],
   "source": [
    "# carregando as predicoes salvas\n",
    "with open (f\"{model_folder}/predictions-{model_nickname}.pkl\", 'rb') as fp:\n",
    "    ans = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41952,
     "status": "ok",
     "timestamp": 1705672888316,
     "user": {
      "displayName": "Ramon Abilio",
      "userId": "08110625410162679749"
     },
     "user_tz": 180
    },
    "id": "pygyNpnrt0aG",
    "outputId": "09274d1f-424f-458a-9e2d-b5a00bcaa344"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from seqeval.metrics import classification_report\n",
    "\n",
    "batch_size = 16\n",
    "refs = []\n",
    "for i in range(0, len(dataset_test['labels']), batch_size):\n",
    "  refs.extend(tokenizer.batch_decode(dataset_test['labels'][ i : i + batch_size], skip_special_tokens=True))\n",
    "\n",
    "refs = [ get_ent_label(t) for t in refs ]\n",
    "\n",
    "\n",
    "predictions = []\n",
    "for i in range(0, len(ans), batch_size):\n",
    "  predictions.extend(tokenizer.batch_decode(ans[ i : i + batch_size], skip_special_tokens=True))\n",
    "\n",
    "predictions = [ get_ent_label(t) for t in predictions ]\n",
    "\n",
    "\n",
    "# fazendo padding para que a listas tenham o mesmo tamanho\n",
    "for idx in range(len(refs)):\n",
    "\n",
    "  if len(refs[idx]) > len(predictions[idx]):\n",
    "    diff = len(refs[idx]) - len(predictions[idx])\n",
    "    predictions[idx] = predictions[idx] + ['O']*diff\n",
    "\n",
    "  if len(refs[idx]) < len(predictions[idx]):\n",
    "    diff = len(predictions[idx]) - len(refs[idx])\n",
    "    refs[idx] = refs[idx] + ['O']*diff\n",
    "\n",
    "print(classification_report(predictions, refs, digits=4, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3691,
     "status": "ok",
     "timestamp": 1705672891995,
     "user": {
      "displayName": "Ramon Abilio",
      "userId": "08110625410162679749"
     },
     "user_tz": 180
    },
    "id": "SnfJQAk-B2iL",
    "outputId": "798c21f1-0a6e-400c-8d21-0bd0ed6ab23a"
   },
   "outputs": [],
   "source": [
    "metric.compute(predictions=predictions, references=refs, zero_division=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise manual das sentenças geradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = dataset['test']\n",
    "\n",
    "for i, row in df_fp[:2].iterrows():\n",
    "  print(i)\n",
    "  print('text     \\t - ',test['text'][row['index']])\n",
    "  print('target   \\t - ',test['target'][row['index']])\n",
    "  print(refs[row['index']])\n",
    "  print(predictions[row['index']])\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "TXff5zPc21PP"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1e885c86c5fe4fc2a5795c1efd178711": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2781b2c6c2004cc8a06991dde91d9800": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_73131803c39a462fbad2e2a32150d31c",
       "IPY_MODEL_ffdd1b8e5645463db8e99aecf3724668",
       "IPY_MODEL_f8d45f7ccc864246942b97166d5fe06f"
      ],
      "layout": "IPY_MODEL_a408860726ef406d87ec946b9bd84de0"
     }
    },
    "73131803c39a462fbad2e2a32150d31c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bda6326bbd7e4d0da0d9aa9fcdfb252e",
      "placeholder": "​",
      "style": "IPY_MODEL_d602c5cd2a864c6a99d3b6477aef185a",
      "value": "Downloading builder script: 100%"
     }
    },
    "73bdb41b61d146aab1281112f335bd35": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9db2193eda5d45f3b8ecad5a052eff01": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a408860726ef406d87ec946b9bd84de0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bda6326bbd7e4d0da0d9aa9fcdfb252e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d602c5cd2a864c6a99d3b6477aef185a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e168f2c257f147dca8e99d640d81ad58": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f8d45f7ccc864246942b97166d5fe06f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_73bdb41b61d146aab1281112f335bd35",
      "placeholder": "​",
      "style": "IPY_MODEL_e168f2c257f147dca8e99d640d81ad58",
      "value": " 6.34k/6.34k [00:00&lt;00:00, 102kB/s]"
     }
    },
    "ffdd1b8e5645463db8e99aecf3724668": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1e885c86c5fe4fc2a5795c1efd178711",
      "max": 6338,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9db2193eda5d45f3b8ecad5a052eff01",
      "value": 6338
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
