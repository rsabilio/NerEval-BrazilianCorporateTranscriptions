{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VkooxbUjQ28w"
   },
   "source": [
    "# Extracting and pre-processing the transcription's text from the PDF files\n",
    "\n",
    "In this notebook, we extract the text from the PDF files, pre-process it, and generate some statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ejU0i7GQyUz"
   },
   "source": [
    "## Installing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26395,
     "status": "ok",
     "timestamp": 1704505116249,
     "user": {
      "displayName": "Ramon Abilio",
      "userId": "08110625410162679749"
     },
     "user_tz": 180
    },
    "id": "IwyvatObQxOK",
    "outputId": "68adf2cc-a825-4b7a-a543-63a1efe9ee10"
   },
   "outputs": [],
   "source": [
    "!pip install -U  pdfplumber"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F2GdPDYvRZkG"
   },
   "source": [
    "## Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9065,
     "status": "ok",
     "timestamp": 1696634656096,
     "user": {
      "displayName": "Ramon Simões Abilio",
      "userId": "03971614869265208899"
     },
     "user_tz": 180
    },
    "id": "_fdIqI-rRcNO",
    "outputId": "8883584d-1beb-4ddf-a47e-d5f2851aa799"
   },
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oAFb8vsfQW1L"
   },
   "outputs": [],
   "source": [
    "folder = './'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_7jY-dl2RWfJ"
   },
   "source": [
    "## Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SOEjUkQXRYj_"
   },
   "outputs": [],
   "source": [
    "# As funções abaixo foram adaptadas de: https://github.com/jsvine/pdfplumber/issues/356#issuecomment-1471361607\n",
    "\n",
    "# Retorna se um objeto não está contido em outro\n",
    "# Por exemplo: se um texto está contido em uma tabela ou figura\n",
    "def not_within_bboxes(obj,bboxes):\n",
    "\n",
    "    def obj_in_bbox(_bbox):\n",
    "        v_mid = (obj[\"top\"] + obj[\"bottom\"]) / 2\n",
    "        h_mid = (obj[\"x0\"] + obj[\"x1\"]) / 2\n",
    "        x0, top, x1, bottom = _bbox\n",
    "        return (h_mid >= x0) and (h_mid < x1) and (v_mid >= top) and (v_mid < bottom)\n",
    "\n",
    "    return not any(obj_in_bbox(__bbox) for __bbox in bboxes)\n",
    "\n",
    "def curves_to_edges(cs):\n",
    "    edges = []\n",
    "    for c in cs:\n",
    "        edges += pdfplumber.utils.rect_to_edges(c)\n",
    "    return edges\n",
    "\n",
    "# Extrai o texto de um arquivo PDF que não está dentro de tabelas ou figuras\n",
    "def raw_text_extract(pdf_file, include_tables=False, include_images=False, show_page_number=False):\n",
    "    page_data = []\n",
    "    with pdfplumber.open(pdf_file) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            #page = pdf.pages[0]\n",
    "\n",
    "            if show_page_number:\n",
    "                print(f\"Pagina: {page.page_number}\")\n",
    "\n",
    "            #print(page.extract_text())\n",
    "            bboxes = []\n",
    "            # identificando as tabelas\n",
    "            if not include_tables:\n",
    "                bboxes = [\n",
    "                    table.bbox\n",
    "                    for table in page.find_tables(\n",
    "                    table_settings={\n",
    "                        \"vertical_strategy\": \"lines\",\n",
    "                        \"horizontal_strategy\": \"lines\",\n",
    "                        \"explicit_vertical_lines\": curves_to_edges(page.curves) + page.edges,\n",
    "                        \"explicit_horizontal_lines\": curves_to_edges(page.curves) + page.edges,\n",
    "                    }\n",
    "                    )\n",
    "                ]\n",
    "            #print(bboxes)\n",
    "\n",
    "            # identificando as imagens\n",
    "            if not include_images:\n",
    "                for image in page.images:\n",
    "                    image_bbox = (image['x0'], image['top'], image['x1'], image['bottom'])\n",
    "                    bboxes.append(image_bbox)\n",
    "                    #print(\"img: \",image_bbox)\n",
    "\n",
    "            # Filtrando os textos que estão fora das caixas das tabelas e das figuras\n",
    "            page = page.filter(lambda obj: not_within_bboxes(obj, bboxes))\n",
    "\n",
    "            # a arquivo bbdc-2015-3T-Transcrição da Teleconferência 3T15.pdf gera caracteres duplicados. Esse método resolve o problema.\n",
    "            # ref: https://github.com/jsvine/pdfplumber/issues/71\n",
    "            text = page.dedupe_chars().extract_text()\n",
    "\n",
    "\n",
    "            ##### removendo cabeçalho: bbdc, bbas, prbc -> \"Transc... ano\": Pode ter ou não \"Transcrição da\"; Pode ter 3 ou 4 linhas\n",
    "\n",
    "            # Transcrição da Teleconferência\n",
    "            # Resultados do 4T09\n",
    "            # Banco do Brasil (BBAS3 BZ) <- esta linha pode nao aparecer no BBDC\n",
    "            # 26 de fevereiro de 2010\n",
    "\n",
    "            # prbc-2013-2T13\n",
    "            # Teleconferência do Paraná Banco\n",
    "            # Resultados do 2° trimestre de 2013\n",
    "            # 14 de junho de 2013 – 11h00 (horário de Brasília)\n",
    "            text = re.sub(r\"(Transcrição da )?Teleconferência(.*)?((?:\\n|\\r\\n?)(.*))?((?:\\n|\\r\\n?)(.*))?(?:\\n|\\r\\n?)(.*)[0-9]{4}( – [0-9]{2}h(.*))?\", '', text).strip()\n",
    "\n",
    "            ##### Removendo cabeçalhos do ITUB\n",
    "            # Itaú Unibanco\n",
    "            # Resultados do Terceiro trimestre de 2018\n",
    "            # 30 de outubro de 2018\n",
    "            text = re.sub(r\"Itaú Unibanco(.*)?((?:\\n|\\r\\n?)(.*))?((?:\\n|\\r\\n?)(.*))?(?:\\n|\\r\\n?)(.*)[0-9]{4}\", '', text).strip()\n",
    "\n",
    "            ##### Removendo cabeçalhos do BBAS\n",
    "            # - Palavra \"#Pública\" (3T19 a 3T22) e #interna (1T21 a 1T22)\n",
    "            text = re.sub(f\"#Pública\", '', text).strip()\n",
    "\n",
    "            # - Palavra \"#interna\" (1T21 a 1T22)\n",
    "            text = re.sub(f\"#interna\", '', text).strip()\n",
    "\n",
    "\n",
    "            # bbas-2006-4T06-Transcrição\n",
    "            # Local Conference Call\n",
    "            # Banco do Brasil Nac. – (29314)\n",
    "            # Resultados do Exercício de 2006\n",
    "            # 28 de Fevereiro de 2007 – 11:00h - horário local\n",
    "            text = re.sub(r\"Local Conference Call(?:\\n|\\r\\n?)(.*)?((?:\\n|\\r\\n?)(.*))?(?:\\n|\\r\\n?)(.*)\", '', text).strip()\n",
    "\n",
    "            # bbas-2009-4T09-Transcrição.pdf\n",
    "            # O padrão é este. As linhas iniciais são removidas na regra anterior, mas fica a linha da data, que é removida aqui\n",
    "            # Transcrição da Teleconferência\n",
    "            # Resultados do 4T09\n",
    "            # Banco do Brasil (BBAS3 BZ)\n",
    "            # 26 de fevereiro de 2010\n",
    "            text = re.sub(r\"^[0-9]{2}(.*)[0-9]{4}\", '', text).strip()\n",
    "\n",
    "            # Relação com Investidores\n",
    "            # Transcrição 1T21\n",
    "            # BANCO DO BRASIL\n",
    "            # TELECONFERÊNCIA\n",
    "            # DE RESULTADOS\n",
    "            # 1T2021\n",
    "            text = re.sub(r\"Relação com Investidores(?:\\n|\\r\\n?)(.*)?((?:\\n|\\r\\n?)(.*))?((?:\\n|\\r\\n?)(.*))?(?:\\n|\\r\\n?)(.*)?(?:\\n|\\r\\n?)(.*)\", '', text).strip()\n",
    "\n",
    "            # bbas-2020-3T20-Transcrição Teleconferência 3T20.pdf\n",
    "            # BANCO DO BRASIL\n",
    "            # TELECONFERÊNCIA\n",
    "            # DE RESULTADOS\n",
    "            # 3T2020\n",
    "            # 06/11/2020\n",
    "            text = re.sub(r\"BANCO DO BRASIL(?:\\n|\\r\\n?)(.*)?((?:\\n|\\r\\n?)(.*))?((?:\\n|\\r\\n?)(.*))?(?:\\n|\\r\\n?)(.*)\", '', text).strip()\n",
    "\n",
    "\n",
    "            # removendo cabeçalho: abcb -> \"Banco ABC Brasil | Relações com Investidores Transcrição da\"\n",
    "            text = re.sub(r\"Banco ABC Brasil \\| (.*)((?:\\n|\\r\\n?))\", '', text).strip()\n",
    "\n",
    "\n",
    "            # removendo o número da página que veio junto do texto\n",
    "            text = re.sub(f\"\\\\n{page.page_number}$\", '', text)\n",
    "\n",
    "            text = re.sub(f'- {page.page_number} -', '', text)\n",
    "\n",
    "\n",
    "            # removendo o número da página que veio junto do texto: bbdc -> \"(cid:1) <pagina>\"\n",
    "            text = re.sub(f\"\\(cid:1\\) {page.page_number}$\", '', text).strip()\n",
    "\n",
    "            # removendo o número da página que veio junto do texto: prbc -> \"Página <pagina>\"\n",
    "            text = re.sub(f\"Página {page.page_number}$\", '', text).strip()\n",
    "\n",
    "            # removendo o número da página que veio junto do texto: itub -> \"1/12\"\n",
    "            text = re.sub(f'{page.page_number}/{len(pdf.pages)}$', '', text).strip()\n",
    "\n",
    "            # removendo o número da página que veio junto do texto: itub -> \"Teleconferência 4T21 2\"\n",
    "            text = re.sub(r'Teleconferência \\dT\\d{2} \\d+$', '', text).strip()\n",
    "\n",
    "            # removendo o número da página que veio junto do texto:\n",
    "            # No abcp-2009-3T09, todas as páginas estão com número \"9\" e\n",
    "            # no abcp-2009-3T09, todas as páginas estão com número 7\n",
    "            head, tail = os.path.split(pdf_file)\n",
    "            if (tail.startswith('abcb-2009')):\n",
    "                if (tail.startswith('abcb-2009-3T09')):\n",
    "                    text = re.sub(r'((?:\\n|\\r\\n?))9$', '', text).strip()\n",
    "                elif (tail.startswith('abcb-2009-4T09')):\n",
    "                    text = re.sub(r'((?:\\n|\\r\\n?))7$', '', text).strip()\n",
    "\n",
    "            page_data.append(text)\n",
    "\n",
    "    return page_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9SXcPC-TeRXY"
   },
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "\n",
    "    text = text.replace(\"\\n\", ' ')\n",
    "    text = text.replace(\"”\", '')\n",
    "    text = text.replace(\"“\", '')\n",
    "    text = text.replace(\"\\\"\", '')\n",
    "    text = text.replace(\"\", '')\n",
    "\n",
    "    #lista com bolinha\n",
    "    text = re.sub(r'(\\s)?(;\\s)?(•)', \"; \", text.strip())\n",
    "    text = re.sub(r'(: ;)', \": \", text.strip())\n",
    "    text = re.sub(r'(\\.;)', \". \", text.strip())\n",
    "\n",
    "    # nu-2021-4T21-Script 4T21.pdf\n",
    "    text = re.sub(r'(; -)', \". \", text.strip())\n",
    "    text = re.sub(r'(\\. -)', \". \", text.strip())\n",
    "    text = re.sub(r'^(-)', \"\", text.strip())\n",
    "    text = re.sub(r'(: \\d.)', ': .', text.strip())\n",
    "    text = re.sub(r'(; e (\\d+\\.)?)', '.', text.strip())\n",
    "    text = re.sub(r'(: ●)', '.', text.strip())\n",
    "    text = re.sub(r'(; ●)', '.', text.strip())\n",
    "    text = re.sub(r'(●)', '', text.strip())\n",
    "\n",
    "    text = re.sub(\"_______________________________________________________________\", \"\", text)\n",
    "\n",
    "    text = re.sub(r\"Sra\\.\", \"Senhora \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\"Sr\\.\", \"Senhor \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\"Srs\\.\", \"Senhores \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'b\\.p\\.\\s([A-Z])', 'bp. \\\\1', text).strip()\n",
    "    text = re.sub('b.p.', 'bp', text).strip()\n",
    "    text = re.sub('p.p.', 'pp', text).strip()\n",
    "    text = re.sub('help!', 'help', text).strip() # bmgb -> tirar a exclamação para evitar quebra de sentenças\n",
    "\n",
    "    text = re.sub('\\s+', ' ', text).strip() # deixar por ultimo, pois as substituicoes anteriores podem inserir multiplos espaços\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1696634656098,
     "user": {
      "displayName": "Ramon Simões Abilio",
      "userId": "03971614869265208899"
     },
     "user_tz": 180
    },
    "id": "EqbqT-sgVdn8",
    "outputId": "48a0d10a-ade4-411a-c528-6fe160a478b6"
   },
   "outputs": [],
   "source": [
    "#text = '-Tivemos um lucro líquido de R$ 70,8 MM, ou seja 11% superior quando comparado com 1S12; -O retorno sobre o capital médio neste semestre foi de 11,8%; -Volume de 957 milhões de originação de crédito consignado neste primeiro semestre, número 26,6% superior, comparado ao 1º semestre 2012; -A carteira de crédito ampliada(considerando avais e fiança) fechou o semestre em R$ 2.648,MM'\n",
    "#text='-A carteira de crédito ampliada(considerando avais e fiança) fechou o semestre em R$ 2.648,MM com um crescimento de 18% sendo que a carteira de middle cresceu expressivos 44% nos últimos 12 meses; -96,5% da carteira de crédito entre níveis AA e C, indicando manutenção da qualidade da carteira;'\n",
    "#text = \"poderá obtê-lo no site do Banco - www.paranabanco.com.br/ri.\"\n",
    "#text='internamente, como nossos cartões de crédito, nossos empréstimos pessoais e nossas soluções de pagamento por celular; e 2. Soluções de terceiros fornecidas por parcei'\n",
    "text='internamente, como nossos cartões de crédito, nossos empréstimos pessoais e nossas soluções de pagamento por celular; e Soluções de terceiros fornecidas por parcei'\n",
    "clean(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MS0N0vU7evLn"
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_sentences(text):\n",
    "    sentences = sent_tokenize(text, language='portuguese')\n",
    "    sentences = [s for s in sentences if len(s.strip()) > 2]\n",
    "    return sentences\n",
    "\n",
    "def get_tokens(text):\n",
    "    tokens = word_tokenize(text, language='portuguese')\n",
    "\n",
    "    return tokens\n",
    "\n",
    "def get_words(text):\n",
    "    tokens = get_tokens(text)\n",
    "\n",
    "    words = [w for w in tokens if w not in string.punctuation]\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J8Rsvm9kfO8y"
   },
   "outputs": [],
   "source": [
    "def save_text(filename, sentences):\n",
    "    with open(filename, 'w') as f:\n",
    "        for row in sentences:\n",
    "            if row != '':\n",
    "                f.write(row+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xSTBdttsfoqj"
   },
   "outputs": [],
   "source": [
    "def generate_stats(text):\n",
    "    stats = {}\n",
    "    tokens = get_tokens(text)\n",
    "    num_tokens = len(tokens)\n",
    "\n",
    "    stats[\"tokens\"] = num_tokens\n",
    "\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7fTxYEjMShJp"
   },
   "source": [
    "## Extraindo e pré-processando textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3817715,
     "status": "ok",
     "timestamp": 1696638474223,
     "user": {
      "displayName": "Ramon Simões Abilio",
      "userId": "03971614869265208899"
     },
     "user_tz": 180
    },
    "id": "Xs9YrCWrR5tH",
    "outputId": "2a9b6999-ea3f-4ee6-e1d6-de1e94435414"
   },
   "outputs": [],
   "source": [
    "transcript_folder = folder+\"pdf-files/\"\n",
    "transcript_text_folder = folder+\"transcricoes_processadas/\"\n",
    "\n",
    "if not os.path.exists(transcript_text_folder):\n",
    "    os.mkdir(transcript_text_folder)\n",
    "\n",
    "global_stats = pd.DataFrame()\n",
    "\n",
    "#Recupera os arquivos que estão na pasta\n",
    "files = os.listdir(transcript_folder)\n",
    "\n",
    "#files = [ f for f in files if f.startswith(\"nu\") ]\n",
    "\n",
    "#files = ['nu-2023-1T23-Transcrição  1T23.pdf']#'abcb-2009-4T09-Transcrição da Teleconferência 4T09.pdf']#'nu-2021-4T21-Script 4T21.pdf']#'prbc-2013-2T13-Transcrição 2T13.pdf']#'itub-2018-3T18-transcrição do áudio.pdf']#'bbdc-2015-2T-Transcrição da Teleconferência 2T15.pdf']#'bbdc-2018-1T-Transcrição da Teleconferência 1T18.pdf']#'bbas-2006-4T06-Transcrição.pdf']#'bbas-2009-4T09-Transcrição.pdf']#'bbas-2020-3T20-Transcrição Teleconferência 3T20.pdf'] #'bbas-2021-1T21-Transcrição 1T21.pdf']#'bbas-2019-3T19-Transcrição Áudio Tele 2T19.pdf']\n",
    "\n",
    "num_files = len(files)\n",
    "for i, file in enumerate(files):\n",
    "    path_transcription = transcript_folder + file\n",
    "\n",
    "    file_name_parts = file.split(\"-\")\n",
    "    ticker          = file_name_parts[0].strip()\n",
    "    trimestre       = file_name_parts[2].strip()\n",
    "\n",
    "    path_folder_ticker = os.path.join(transcript_text_folder, ticker)\n",
    "    if not os.path.exists(path_folder_ticker):\n",
    "        os.mkdir(path_folder_ticker)\n",
    "\n",
    "    if os.path.isfile(path_transcription):\n",
    "        print(f\"Processando arquivo {i+1} de {num_files}\")\n",
    "\n",
    "        print(\"*** Extraindo texto do PDF: \"+ file)\n",
    "        path_transcription = transcript_folder + file\n",
    "        if ticker in ['bbas', 'bbdc']:\n",
    "            page_data = raw_text_extract(path_transcription)\n",
    "        else:\n",
    "            page_data = raw_text_extract(path_transcription, include_tables=True, include_images=False)\n",
    "\n",
    "        #print(page_data)\n",
    "        print(\"*** Limpando o texto\")\n",
    "        text = \" \".join(page_data)\n",
    "        text = clean(text)\n",
    "        #print(text)\n",
    "\n",
    "        print(\"*** Gerando sentenças\")\n",
    "        sentences = get_sentences(text)\n",
    "        num_sentences = len(sentences)\n",
    "        sentences = ['ticker;ano;trimestre;sentenca']+[f'{ticker};{file_name_parts[1]};{trimestre};\"{s}\"' for s in sentences]\n",
    "\n",
    "        #[ print(s) for s in sentences ]\n",
    "\n",
    "        print(\"*** Gerando estatísticas\")\n",
    "\n",
    "        stats = {}\n",
    "        stats['origem']    = ticker\n",
    "        stats['trimestre'] = trimestre\n",
    "        stats['sentencas'] = num_sentences\n",
    "\n",
    "        # concatenando os dois dicts\n",
    "        stats = {**stats, **generate_stats(text)}\n",
    "\n",
    "        print(\"*** Salvando arquivo com a sentenças\")\n",
    "        save_text(f\"{path_folder_ticker}/{ticker}-{file_name_parts[1]+'-'+trimestre}.csv\", sentences)\n",
    "\n",
    "        global_stats = pd.concat([global_stats, pd.DataFrame.from_dict([stats])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 307,
     "status": "ok",
     "timestamp": 1696639438782,
     "user": {
      "displayName": "Ramon Simões Abilio",
      "userId": "03971614869265208899"
     },
     "user_tz": 180
    },
    "id": "L3VXz2DHlkbp",
    "outputId": "22e3b8d4-3bc4-4c95-ac95-9f6e5b5117a1"
   },
   "outputs": [],
   "source": [
    "global_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6aafBCxv6EEU"
   },
   "outputs": [],
   "source": [
    "global_stats.to_csv(transcript_text_folder + '/global_stats.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1540,
     "status": "ok",
     "timestamp": 1696639459281,
     "user": {
      "displayName": "Ramon Simões Abilio",
      "userId": "03971614869265208899"
     },
     "user_tz": 180
    },
    "id": "dELTOJ59c1W2",
    "outputId": "0cfa9f03-2d0d-4a2d-e5ac-d21b74731d3c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# reunindo todos os arquivos em um só\n",
    "dataset = transcript_text_folder+'/dataset-completo.csv'\n",
    "\n",
    "print(f\"Transcripts folder: {transcript_text_folder}\")\n",
    "dirs = os.listdir(transcript_text_folder)\n",
    "\n",
    "dirs = [ d for d in dirs if os.path.isdir(os.path.join(transcript_text_folder, d)) ]\n",
    "print(dirs)\n",
    "#dirs = ['nu']\n",
    "num_dirs = len(dirs)\n",
    "print(f\"Num dirs: {num_dirs}\")\n",
    "with open(dataset, 'w') as ds:\n",
    "    ds.write(f\"ticker;ano;trimestre;sentenca\\n\")\n",
    "    for i, dir in enumerate(dirs):\n",
    "        if dir != 'processadas':\n",
    "            print(f\"Dir: {dir} ({i+1}/{num_dirs})\")\n",
    "            path_transcription = os.path.join(transcript_text_folder, dir)\n",
    "\n",
    "            files = os.listdir(path_transcription)\n",
    "            num_files = len(files)\n",
    "            for f_num, filename in enumerate(files):\n",
    "                print(f\"\\tFile: {filename} ({f_num+1}/{num_files})\")\n",
    "                path_file = os.path.join(path_transcription, filename)\n",
    "\n",
    "                if os.path.isfile(path_file):\n",
    "                    with open(path_file) as f:\n",
    "                        #pula a linha do cabeçalho dos arquivos\n",
    "                        ds.writelines(f.readlines()[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vy1LUKX9J_sq",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Análise dos dados extraídos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 895,
     "status": "ok",
     "timestamp": 1696639466196,
     "user": {
      "displayName": "Ramon Simões Abilio",
      "userId": "03971614869265208899"
     },
     "user_tz": 180
    },
    "id": "3VjMyXd22xi5",
    "outputId": "16267aaa-41fa-40e5-8aba-532cf3e93a2a"
   },
   "outputs": [],
   "source": [
    "dataset = transcript_text_folder +'/dataset-completo.csv'\n",
    "\n",
    "df = pd.read_csv(dataset, sep=';')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 21818,
     "status": "ok",
     "timestamp": 1696639491022,
     "user": {
      "displayName": "Ramon Simões Abilio",
      "userId": "03971614869265208899"
     },
     "user_tz": 180
    },
    "id": "jZRx1J6HGZuh",
    "outputId": "a58034d6-591b-4be0-eb70-5583e40e329b"
   },
   "outputs": [],
   "source": [
    "# adicionando contagem de palavras\n",
    "df['num_palavras'] = [ len(get_words(s)) for s in df['sentenca'].values]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rpr-5NafKNu3"
   },
   "outputs": [],
   "source": [
    "df.to_csv(f\"{transcript_text_folder}/dados-completos-com-num-palavras.csv\", sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 397,
     "status": "ok",
     "timestamp": 1696639609400,
     "user": {
      "displayName": "Ramon Simões Abilio",
      "userId": "03971614869265208899"
     },
     "user_tz": 180
    },
    "id": "99gDsS3zIbN2",
    "outputId": "1a3abfa4-636c-4c1a-e2c8-0bb72f661112"
   },
   "outputs": [],
   "source": [
    "df[df['num_palavras'] < 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 341,
     "status": "ok",
     "timestamp": 1696639560043,
     "user": {
      "displayName": "Ramon Simões Abilio",
      "userId": "03971614869265208899"
     },
     "user_tz": 180
    },
    "id": "h67A6sH0Fq9k",
    "outputId": "016f2fa0-2829-4b6f-fb2a-4a925c5f4293"
   },
   "outputs": [],
   "source": [
    "df[df.duplicated(subset=['sentenca'])].sort_values(by='sentenca')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2090,
     "status": "ok",
     "timestamp": 1696640159213,
     "user": {
      "displayName": "Ramon Simões Abilio",
      "userId": "03971614869265208899"
     },
     "user_tz": 180
    },
    "id": "DqosJ_H205ID",
    "outputId": "369e8f7f-f7cf-4d38-e552-3044a848e2d4"
   },
   "outputs": [],
   "source": [
    "print(f\"Quantidade de sentenças: {len(df)}\")\n",
    "\n",
    "df_duplicatas = df[df.duplicated(subset=['sentenca'])].sort_values(by='sentenca')\n",
    "df_duplicatas.to_csv(f\"{transcript_text_folder}/dataset-sentencas-duplicadas.csv\", sep=';', index=False)\n",
    "print(f\"Quantidade de duplicatas: {len(df_duplicatas)}\")\n",
    "\n",
    "df_sem_duplicatas = df.drop_duplicates(subset=['sentenca'])\n",
    "df_sem_duplicatas.to_csv(f\"{transcript_text_folder}/dataset-sem-sentencas-duplicadas.csv\", sep=';', index=False)\n",
    "print(f\"Quantidade de sentenças sem duplicatas: {len(df_sem_duplicatas)}\")\n",
    "\n",
    "df_maiores_que_4 = df_sem_duplicatas[df_sem_duplicatas['num_palavras'] > 4]\n",
    "df_maiores_que_4.to_csv(f\"{transcript_text_folder}/dataset-com-sentencas-maiores-que-4-palavras.csv\", sep=';', index=False)\n",
    "print(f\"Quantidade de sentenças com mais de 4 palavras: {len(df_maiores_que_4)}\")\n",
    "\n",
    "df_menores_que_5 = df_sem_duplicatas[df_sem_duplicatas['num_palavras'] < 5]\n",
    "df_menores_que_5.to_csv(f\"{transcript_text_folder}/dataset-com-sentencas-menores-que-5-palavras.csv\", sep=';', index=False)\n",
    "print(f\"Quantidade de sentenças com menos de 5 palavras: {len(df_menores_que_5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 695
    },
    "executionInfo": {
     "elapsed": 4089,
     "status": "ok",
     "timestamp": 1696640610047,
     "user": {
      "displayName": "Ramon Simões Abilio",
      "userId": "03971614869265208899"
     },
     "user_tz": 180
    },
    "id": "kitfF2yTotCA",
    "outputId": "f9c6b8f9-2c10-4e55-c157-032bd8dd3843"
   },
   "outputs": [],
   "source": [
    "df_maiores_que_4.hist(column='num_palavras', by='ano', sharex=True, figsize=(10,8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "executionInfo": {
     "elapsed": 292,
     "status": "ok",
     "timestamp": 1696640299057,
     "user": {
      "displayName": "Ramon Simões Abilio",
      "userId": "03971614869265208899"
     },
     "user_tz": 180
    },
    "id": "5PFHgmuBpEuu",
    "outputId": "7dbe2fd3-76c9-429c-aa12-d42e6f9fdeba"
   },
   "outputs": [],
   "source": [
    "df_maiores_que_4.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 676
    },
    "executionInfo": {
     "elapsed": 314,
     "status": "ok",
     "timestamp": 1696640933713,
     "user": {
      "displayName": "Ramon Simões Abilio",
      "userId": "03971614869265208899"
     },
     "user_tz": 180
    },
    "id": "Sxrq04fNrJ_X",
    "outputId": "89adde0c-8b0d-481c-b302-bd505301589a"
   },
   "outputs": [],
   "source": [
    "df_maiores_que_4.groupby(by='ano').agg({'num_palavras':('min','max','mean', 'std')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 348
    },
    "executionInfo": {
     "elapsed": 315,
     "status": "ok",
     "timestamp": 1696641151400,
     "user": {
      "displayName": "Ramon Simões Abilio",
      "userId": "03971614869265208899"
     },
     "user_tz": 180
    },
    "id": "aHBsmjcbsUxH",
    "outputId": "60c18eac-7b78-45b9-d8d0-8506c558725f"
   },
   "outputs": [],
   "source": [
    "df_maiores_que_4[df_maiores_que_4['num_palavras'] > 250]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
